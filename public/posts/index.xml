<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on LLaMatters by Chirag Mehta</title>
    <link>https://llamatters.chir.ag/posts/</link>
    <description>Recent content in Posts on LLaMatters by Chirag Mehta</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Jul 2023 21:58:15 -0500</lastBuildDate><atom:link href="https://llamatters.chir.ag/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Agents make LLMs awesome | Why using system prompts to setup agents with roles matters</title>
      <link>https://llamatters.chir.ag/posts/agents/</link>
      <pubDate>Thu, 27 Jul 2023 21:58:15 -0500</pubDate>
      
      <guid>https://llamatters.chir.ag/posts/agents/</guid>
      
      <description>Context is important. It is important in life, and it is important in large language models (LLMs). You would not ask your doctor questions about your car, and you would not ask your electrician questions about your health. Yet most of us open a new session of ChatGPT and immediately ask why the car is making a noise when starting or what could cause sharp lower back pain. The response we get will be generic and often useless.
What we need to provide is context, either as part of the initial question or if the interface allows it, via a system prompt.
This is the system prompt I use any time I have a medical question for ChatGPT or my local LLM:
You are a health advisor named Medy that efficiently diagnoses users&amp;amp;rsquo; medical issues without using generic warnings or disclaimers. Medy should ask necessary follow-up questions to understand the situation and suggest possible solutions. Medy may explain a terminology when using it the first time by putting the description within parentheses. Medy does not show</description>
      
    </item>
    
    
    
    <item>
      <title>Readability Demo | Rewriting text to any comprehension level or length</title>
      <link>https://llamatters.chir.ag/posts/readability-demo/</link>
      <pubDate>Sun, 16 Jul 2023 14:03:53 -0500</pubDate>
      
      <guid>https://llamatters.chir.ag/posts/readability-demo/</guid>
      
      <description></description>
      
    </item>
    
    
    
    <item>
      <title>Readability | Rewriting text to any comprehension level or length</title>
      <link>https://llamatters.chir.ag/posts/readability/</link>
      <pubDate>Thu, 13 Jul 2023 05:55:27 -0500</pubDate>
      
      <guid>https://llamatters.chir.ag/posts/readability/</guid>
      
      <description>Wikipedia is a great resource for getting a quick overview of a topic. But sometimes the articles are too long or too technical. Simple Wikipedia helps, although it can still be pretty lengthy and not always simple enough. Or it might be too simple, depending on what I am trying to learn. I&amp;amp;rsquo;ve always wanted to be able to choose the level of detail and length based on what I am looking. Sometimes when I am researching a new topic and come across 10 new terms, all linking to their own detailed Wikipedia pages, I just want to get a 50-100 word gist. Other times, I want to get a 1000-word summary of a topic I am sort of familiar with but don&amp;amp;rsquo;t know well enough.
I have this same need for other text-based content like news articles and technical documents. And I believe a solution for this would improve readability and thus improve comprehension for everyone.
Readability &amp;amp;amp; Comprehension ðŸ”—Readability refers to the ease with which a reader can read and understand a written text. It is influenced by</description>
      
    </item>
    
    
    
    <item>
      <title>Introduction | Why you may want to follow this blog</title>
      <link>https://llamatters.chir.ag/posts/introduction/</link>
      <pubDate>Thu, 29 Jun 2023 15:47:24 -0500</pubDate>
      
      <guid>https://llamatters.chir.ag/posts/introduction/</guid>
      
      <description>As a user, ChatGPT is helpful. For many, it is an easy way to answer detailed questions or write essays and emails. But for those who wish to learn more, it can be a gateway into the world of large language models (LLMs), generative text, and context-aware responses. ChatGPT by OpenAI is a fantastic tool and at the moment, far ahead of its competitors, but it is just one way of using conversational language to interact with computers. There is so much more happening in this field, especially in online communities like r/LocalLLaMA, that is redefining how we will eventually write and use software, but is not common-knowledge yet. With this blog, I hope to share my thoughts on where this field is going in non-programmer terms, how others could use or rather improve their use of these tools, and what I personally hope to get/make for myself.
Background ðŸ”—I have always loved languages, dictionaries, poetry, essays, word games, and crossword puzzles. Years ago, I analyzed US Presidential speeches and built a</description>
      
    </item>
    
  </channel>
</rss>